{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = ''\n",
    "chapter_id = 'Regresion'\n",
    "images_path = os.path.join(root, 'images',chapter_id)\n",
    "os.makedirs(images_path,exist_ok=True)\n",
    "\n",
    "def save_fig (fig_id, tigh_layout=True, fig_extension='png',resolution=True):\n",
    "    path = os.path.join(images_path,fig_id + '.'+fig_extension)\n",
    "    print('save figure',fig_id)\n",
    "    if tigh_layout:\n",
    "        plt.tigh_layout()\n",
    "    plt.savefig(path,format=fig_extension,resolution=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set up \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "print(housing['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data ke train & test\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing['data'],housing['target'],random_state=42)\n",
    "# split data train ke valid dan train\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,y_train_full,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15480, 8)\n",
      "(15480,)\n",
      "(5160, 8)\n",
      "(5160,)\n",
      "(20640, 8)\n",
      "(20640,)\n"
     ]
    }
   ],
   "source": [
    "#housing di split ke dalam train dan testing\n",
    "print(X_train_full.shape)\n",
    "print(y_train_full.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(housing['data'].shape)\n",
    "print(housing['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing train data di split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 2s 1ms/step - loss: 1.6419 - accuracy: 0.0028 - val_loss: 0.8077 - val_accuracy: 0.0044\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.7047 - accuracy: 0.0029 - val_loss: 0.6736 - val_accuracy: 0.0044\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 858us/step - loss: 0.6345 - accuracy: 0.0029 - val_loss: 0.6243 - val_accuracy: 0.0044\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.5977 - accuracy: 0.0029 - val_loss: 0.5977 - val_accuracy: 0.0044\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.5706 - accuracy: 0.0029 - val_loss: 0.5708 - val_accuracy: 0.0044\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.5472 - accuracy: 0.0029 - val_loss: 0.5538 - val_accuracy: 0.0044\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.5288 - accuracy: 0.0029 - val_loss: 0.5370 - val_accuracy: 0.0044\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.5130 - accuracy: 0.0029 - val_loss: 0.5257 - val_accuracy: 0.0044\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 855us/step - loss: 0.4992 - accuracy: 0.0029 - val_loss: 0.5142 - val_accuracy: 0.0044\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 851us/step - loss: 0.4875 - accuracy: 0.0029 - val_loss: 0.5040 - val_accuracy: 0.0044\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.4777 - accuracy: 0.0029 - val_loss: 0.4977 - val_accuracy: 0.0044\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4688 - accuracy: 0.0029 - val_loss: 0.4894 - val_accuracy: 0.0044\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.4615 - accuracy: 0.0029 - val_loss: 0.4848 - val_accuracy: 0.0044\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4547 - accuracy: 0.0029 - val_loss: 0.4804 - val_accuracy: 0.0044\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4488 - accuracy: 0.0029 - val_loss: 0.4747 - val_accuracy: 0.0044\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4435 - accuracy: 0.0029 - val_loss: 0.4713 - val_accuracy: 0.0044\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4389 - accuracy: 0.0029 - val_loss: 0.4672 - val_accuracy: 0.0044\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4347 - accuracy: 0.0028 - val_loss: 0.4642 - val_accuracy: 0.0044\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4306 - accuracy: 0.0028 - val_loss: 0.4629 - val_accuracy: 0.0044\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4273 - accuracy: 0.0028 - val_loss: 0.4603 - val_accuracy: 0.0044\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation ='relu',input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)    \n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error',optimizer=keras.optimizers.SGD(learning_rate=1e-3),metrics='accuracy')\n",
    "history = model.fit(X_train,y_train,epochs=20,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 596us/step - loss: 0.4190 - accuracy: 0.0021\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3276103],\n",
       "       [1.7185786],\n",
       "       [3.3415678]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.477  , 0.458  , 5.00001])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.641871</td>\n",
       "      <td>0.002756</td>\n",
       "      <td>0.807653</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.704697</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.673631</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.634542</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.624266</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.597736</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.597663</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570629</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.570844</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.547246</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.553816</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.528757</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.536956</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.513012</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.525667</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.499158</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.514190</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.487499</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.504004</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.477734</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.497688</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.468763</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.489350</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.461510</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.484831</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.454718</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.480385</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.448771</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.474707</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.443471</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.471332</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.438877</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.467211</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.434657</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.464209</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.430618</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.462881</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.427323</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.460256</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.641871  0.002756  0.807653      0.004393\n",
       "1   0.704697  0.002929  0.673631      0.004393\n",
       "2   0.634542  0.002929  0.624266      0.004393\n",
       "3   0.597736  0.002929  0.597663      0.004393\n",
       "4   0.570629  0.002929  0.570844      0.004393\n",
       "5   0.547246  0.002929  0.553816      0.004393\n",
       "6   0.528757  0.002929  0.536956      0.004393\n",
       "7   0.513012  0.002929  0.525667      0.004393\n",
       "8   0.499158  0.002929  0.514190      0.004393\n",
       "9   0.487499  0.002929  0.504004      0.004393\n",
       "10  0.477734  0.002929  0.497688      0.004393\n",
       "11  0.468763  0.002929  0.489350      0.004393\n",
       "12  0.461510  0.002929  0.484831      0.004393\n",
       "13  0.454718  0.002929  0.480385      0.004393\n",
       "14  0.448771  0.002929  0.474707      0.004393\n",
       "15  0.443471  0.002929  0.471332      0.004393\n",
       "16  0.438877  0.002929  0.467211      0.004393\n",
       "17  0.434657  0.002842  0.464209      0.004393\n",
       "18  0.430618  0.002842  0.462881      0.004393\n",
       "19  0.427323  0.002842  0.460256      0.004393"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(history.history)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnLklEQVR4nO3deZhcdZ3v8fe3a6+u6r3T2TorYUkCWVkUgWZECcwYFqMDOIgok3GEUR9m0Tvey1WcGS96cRwFUQcRBDWgXjAgGgQTQCFAokmAhISQrbN2kt636q7u3/2jqjvdnd7oPac/r+c5T53lV6e+dbr6U6d+dc4pc84hIiKnvozRLkBERIaGAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDyiz0A3swfMrMzM3uhhuZnZt81sp5ltMbPFQ1+miIj0pT976A8Cy3pZfgUwJz2sBO4bfFkiIvJu9RnozrkXgPJemlwF/NilrAdyzGzSUBUoIiL94x+CdUwBSjtM70/PO9S1oZmtJLUXTyQSWVJcXDygB2xtbSUjo+8PF1UJR0XCMT0rAxvQIw1Mf+sbLapvcMZ6fTD2a1R9A7djx45jzrnCbhc65/ocgBnAGz0sewp4X4fp54Clfa1zyZIlbqDWrl3br3Y/Wb/XTf/CU+5QZcOAH2sg+lvfaFF9gzPW63Nu7Neo+gYO2OB6yNWheAs6AHTc1Z6anjfq8jIDAJTXNY1yJSIiw28oAn018PH00S4XAFXOuZO6W0ZDbjQIQEW9Al1EvK/PPnQz+xlQAhSY2X7gfwMBAOfc94CngSuBnUA9cPNwFftu5WWmAl176CIyHvQZ6M656/tY7oBbh6yiIZSbqT10ERk/xubXuEMkJ6I+dBEZPzwd6H5fBtmRgAJdRMYFTwc6QH5mUIEuIuOC5wM9NzOoPnQRGRe8H+jRIOV1zaNdhojIsPN8oOdlBqhQl4uIjAOeD/TczCDl9U1tlyUQEfEszwd6XjRIU7KV+qaW0S5FRGRYeT7Qc3W2qIiME54P9LyoAl1ExgfvB3osHeg6dFFEPM77gd52xUXtoYuIx3k+0NWHLiLjhecDPSvsx5dhOltURDzP84FuZjpbVETGBc8HOuhsUREZH8ZFoKf20BXoIuJt4yLQ89Kn/4uIeNm4CXR1uYiI142fQK9vorVVF+gSEe8aF4GeGw3S6qC6UUe6iIh3jYtAz9PJRSIyDoyLQG87W1QnF4mIl42LQD9xxUV1uYiId42LQM/NDABQXpcY5UpERIbPuAj0/MwQoD10EfG2cRHokaCPcCBDfegi4mnjItAh1Y+uo1xExMvGTaDn6mxREfG4cRPoup6LiHjduAn03Kj20EXE28ZNoOdlBjmuQBcRDxs3gZ4bDVLTmKS5pXW0SxERGRbjJtDzYjr9X0S8bfwEevr0/wqdXCQiHtWvQDezZWa23cx2mtkXu1k+zczWmtmfzWyLmV059KWmbCrbxKPHH8W5d3dt8xOn/2sPXUS8qc9ANzMfcC9wBTAXuN7M5nZp9j+Bx5xzi4DrgO8OdaFtdlbu5A+1f+DZfc++q/vl6YqLIuJx/dlDPw/Y6Zzb5ZxrAlYBV3Vp44Cs9Hg2cHDoSuzs6tOuZmJgIt/a+C2aW/rffXLiiosKdBHxJuur68LMVgDLnHO3pKdvBM53zt3Woc0k4BkgF8gELnPObexmXSuBlQBFRUVLVq1aNaCiN5Rv4KGah1iRu4JLsi7p132SrY5bnqnn2jkBls8ODuhx+6u2tpZYLDasjzEYqm9wxnp9MPZrVH0Dd+mll250zi3tbpl/iB7jeuBB59zdZvYe4GEzm++c63SMoHPuB8APAJYuXepKSkoG9GBurWNb5jaeq3iO25fdTjwY79f94s+vIatwCiUl8wb0uP21bt06BvrcRoLqG5yxXh+M/RpV3/DoT5fLAaC4w/TU9LyOPgU8BuCcexkIAwVDUWB3zIzbl95ORaKCB954oN/3y03/WLSIiBf1J9BfA+aY2UwzC5L60nN1lzb7gPcDmNlZpAL96FAW2tW8/HlcOfNKHt76MIfrDvfrPnmZuuKiiHhXn4HunEsCtwFrgG2kjmZ508zuNLPl6Wb/CPytmW0GfgZ8wr3b4woH4LOLP0ura+WeP9/Tr/Z52kMXEQ/rVx+6c+5p4Oku8+7oML4VuHBoS+vblNgUPnbWx3jozYe4ce6NnJF3Rq/tc6NBth+uGaHqRERG1il/pugtZ99CPBjnmxu/2WfbvMyAulxExLNO+UDPDmWz8pyVvHTwJV468FKvbXMzgzQ0t9DQ1DJC1YmIjJxTPtABrj/zeqbEpvDNjd+kpbXnsG6/nov60UXEgzwR6EFfkM8t/hzbK7bz1K6nemyXm6mzRUXEuzwR6ACXz7icefnz+M6fv0NjsrHbNvkKdBHxMM8EeoZl8I9L/5Ej9Ud4ZNsj3bbJ1QW6RMTDPBPoAOdOPJeSqSX88PUfUt5YftJyXaBLRLzMU4EO8Pkln6c+Wc/3N3//pGVZkQAZhn4sWkQ8yXOBPjtnNtfOuZbHtj/Gvup9nZb5MoycaJBydbmIiAd5LtABbl14KwFfgG/96VsnLcuNBvQzdCLiSZ4M9IJIATfPu5nf7f0dm8o2dVqWlxnkeF1idAoTERlGngx0gJvm3URBpIC7N9zd6fdHc6NB7aGLiCd5NtCjgSifWfgZNh3dxO/3/b59fn5Mfegi4k2eDXSAa067hlnZs/jPP/0nza2pvfLUHnoTI3B1XxGREeXpQPdn+Ll9ye3srd7LL3b8AoCJ2WGSrY7Vm4ftd6xFREaFpwMd4OKpF7O0aCnf2/w9aptq+fDiqZw/M4/PP7qJR1/b1/cKREROEZ4PdDPjn5b+E+WN5TzwxgNkhvw8ePN5XDynkC/88nUe+MPu0S5RRGRIeD7QAeYVzOOKmVfw8NaHOVJ3hEjQxw8+voRl8yZy51NbuXftztEuUURk0MZFoAN8dtFnaXEt3LMp9fujIb+Pe25YxDWLpvCNNdu567dv6YtSETmljZtAnxqfyvVnXs+vdv6KHRU7APD7Mrj7Iwu44fxp3LfuHb68+k1aWxXqInJqGjeBDrDynJXEgjHu3nB3+y8bZWQY/371fP72opk89PJevvDLLbQo1EXkFDSuAj07lM2tC2/lpYMvcdNvb2JP1R4g9cXpv155Fp+/bA4/37ifz636M80traNbrIjIuzSuAh3ghjNv4GsXfY3dVbtZ8eQKfvzmj2lpbcHM+Pxlp/OvV57JU1sO8fePbKSxWT8mLSKnjnEX6GbGX836K5646gneM+k9fGPDN7h5zc3srd4LwMqLZ/PVq+fz7LYyPvXQa9QlkqNcsYhI/4y7QG9TGC3k23/xbf79ff/OzsqdrFi9gke2PkKra+XGC6Zz90cW8PI7x/n4A69S1aCLeYnI2DduAx1Se+vLZy/n8eWPc+7Ec7nrtbv45JpPUlpdyoeXTOXeGxazZX8lH7t/vX62TkTGvHEd6G2KMou49/338tULv8r28u18+MkP89NtP+Xy+UX84MalvH2klr/+/suUVTeOdqkiIj1SoKeZGVefdjWPX/U4i4sW87VXv8Ytz9zCnClN/OjmczlQ2cBHvv8y+yvqR7tUEZFuKdC7mJg5kfvefx9fee9X2Hp8K9euvpbS5uf48afOpaKuiY9+72V2Ha0d7TJFRE6iQO+GmXHtnGt5fPnjLCxcyL+98m98760v8F83TieRbGXF917mR3/crcMaRWRMUaD3YlJsEt//wPe54z138Pqx1/ni+pv41JWHmVOUyVee3MrFX1+rYBeRMUOB3gcz4yOnf4THr3qcswvP5r43vk5s+g/5l2uamVEYVLCLyJjhH+0CThWTY5P57w/8Nz/f8XO+u+m7vHr4f5EVz+IvL72EffvO5CtPNnLfunf4+5LZTGnRtWBEZOQp0N8FM+OjZ3yUa+dcyyuHXuHJXU/y+33P0hB8kpkLJ0HdYu5cs58sm8D+0G5uOH8a4YBvtMsWkXGiX4FuZsuA/wJ8wP3Ouf/TTZuPAl8GHLDZOXfDENY5pvgz/Fw45UIunHIh9c31PLfvOZ7a9RTrm35DbPav8TUX87U/LuS7L57LZy5aqGAXkRHRZ6CbmQ+4F/gAsB94zcxWO+e2dmgzB/gfwIXOuQozmzBcBY810UCUD83+EB+a/SHK6sv4ze7fsGrzKpoDT5Jwv+Ybm+dwz6vn8XdLl3PTe+Yo2EVk2PRnD/08YKdzbheAma0CrgK2dmjzt8C9zrkKAOdc2VAXeiqYEJ3ATfNuYvrR6UxZMIWndj3F4zuepKLpYb6z8zHue2MBV5/2If75kivJDAVHu1wR8Rjr62fXzGwFsMw5d0t6+kbgfOfcbR3aPAHsAC4k1S3zZefcb7tZ10pgJUBRUdGSVatWDajo2tpaYrHYgO47EjrW1+pa2ZnYybPlr/JWYjMuoxGSWUxxi/lg/vkszp06qvWNRapv8MZ6japv4C699NKNzrml3S50zvU6ACtI9Zu3Td8I3NOlzVPA40AAmAmUAjm9rXfJkiVuoNauXTvg+46EnupraG5w317/c3fRgx9z8350jpv/4Hy36P5l7u9Xf9NtKysd9frGCtU3eGO9RtU3cMAG10Ou9uc49ANAcYfpqel5He0HVjvnmp1zu0ntrc/p19vNOBL2h/mH81fwwk2PsHr5M7y/cCUZ5uPF8gdY8esrufDB6/nqukeobNClBUTk3etPoL8GzDGzmWYWBK4DVndp8wRQAmBmBcDpwK6hK9N7ZuUV8a0r/4ENn3yK71z0M86OXU1NywEe23sXF60q4YqffIaH/vRs+2+fioj0pc8vRZ1zSTO7DVhDqn/8Aefcm2Z2J6ld/9XpZR80s61AC/DPzrnjw1m4l5TMmk/JrPkkW1p4ZNNaVm17gtLEK/zf11/k7k05zM8u4dNLPsrFM84e7VJFZAzr13Hozrmngae7zLujw7gDbk8PMkB+n49PLLmMTyy5jON1tdz7ymrW7P01W2pWc+vzTxBaW8z7Jl7OZ8//KLPyJo12uSIyxuhM0TEqPzPGHX9xA3dwA1vLDvCd9b9g/dFneK7sfp578n7CbjJn5p7N5ae9h4uLz6U4XoyZjXbZIjKKFOingLkTpnDf8s/h3GdZs2MLD21+ircqtvDn48+zqXINd22AqC+HhYULee/UpSyasIiz8s4i4AuMdukiMoIU6KcQM2PZGQtYdsYCnHO8cbCSxzZvZN2eVzjavJ0/NGzhpcPrAAhmBDm78GwWTVjEogmLWFC4gOxQ9ug+AREZVgr0U5SZcfaUXM6echlwGXuO1bHmzcP8eut2tpZvoSmyl82JUv505Ec47gdgdvZsFk5YSKQ2wqzqWeqmEfEYBbpHzCjI5O8umc3fXTKbsuq/4JmtR1jz5mFe3nEIF9pHds4Bav0HeXrXb2loqeORxx8hP5zPwgkLWVi4kIUTFjI3fy5Bny5JIHKqUqB70ISsMH9zwXT+5oLpVNU38/vtR1jzxhGef+soDc3NRKNlnDa9nLC/lDeOvsVz+54DUt008wrmdQr5vHDeKD8bEekvBbrHZUcDXLNoKtcsmkpDUwsvvn2UR9ZuZl/ZLLZsmwtcTlZmI3OmHSMe309NYicPb32YH7X+CIAZWTNYULiARRMWsXDCQmZmzyTD9ENXImORAn0ciQR9fHDeRIJH36KkpISDlQ28svs4698pZ/3uPDZumwpcQHYU5s+oJjfvAA0Z7/DC/hf41Tu/AiArmMU5hecwK3sWM7NnMiNrBjOyZ5Afzld/vMgoU6CPY5NzIu177wAHKht4Zddx1u86zsu7jvPy1izgLHKiV7N4RpLCwkMkA7sord/Oa4dfI9GSaF9XPBBnRvaMTiE/I2sG07KmEfKFRukZiowvCnRpNyUnwrWLp3Lt4lTA76+o55Vd5e0B//zWScAkcqMlLCjOYvakJAW5VQTCxzjcUMqe6j2sP7Se1e+cuNRPhmUwOXNye8DPzJ7ZPmivXmRoKdClR1Nzo0xdEuXDS1IBX1pezyu7y3l193E2lVby/I5aUldPLmBG/jQWFv8lNxbncObkEJHMcg7U7mNP9R52V+1mT/UeNh7ZSEOyoX398UA8tUef3rOfmZUK+qRLjs4TFjnFKdCl34rzohTnRVmRDviaxmZeP1DFptJKNpdW8vKu4zyx6SAAQV8GZ03OZlHxJby3eDmfmZfLtLwwRxuOsqtqF3uqUkG/u3r3yXv1ZDDt8WknBf3M7Jk6OUqkFwp0GbB4OMB7Zxfw3tkF7fMOVTWwaV8lm/ZXsmlfJY9tKOXBl/YAkB0JsKA4h4XFBcybPIuLTs9iam4EM6OuuY49VXvYVbWL57c8T2tuK7urdvPHA3+kubW5ff154bz2vvnieDHF8WKmxacxNT5VYS/jngJdhtSk7AiTzo5wxdmpq0G2tDreLqtJhXxparjn92/Tmv7lw6ywn7MmZTFvcjZzJ2czd9IlRLJjXFZyafr+LRysPcju6t2pPfr08McDf+Row9FOj50dyqY4lgr54qwTYV8cL6YgUqD+evE8BboMK1+GcebELM6cmMV1500DoKGphe1HanjzYBVbD1az9VA1P3t1Hw3NqR/z8Bmc8fqLzJ2cxdxJWcydnMXCye/h4qkXd1p3fXM9+2v3U1pTyv6a/eyr3kdpTSmvH3udZ/Y+Q4s78eMgEX+EqfGpFMeKmRqfSkGkgLxwXmqI5JEfzic3nKsjcuSUpkCXERcJ+lhYnMPC4pz2eS2tjt3H6th6qJrfrn+D2kCIddvL+MXG/e1tivMizJ2UxVmTspgzIc7sCZnMyJ/N6bmnn/QYza3NHKo9RGlNKftqUkFfWlPK3uq9vHTwJRpbGrutLRaInQj6dNjnhnLJj+S3zzvUdIjqpmrigbj2+mVMUaDLmODLME6bEOO0CTGyKnZQUnIeAGU1jbx5sLp9T37bwWqe2XokfXQNZFjqy9rTCmPMnhBL32ZyWmGcaVnTmJY1jQu5sNNjOedoSDZwvPE45Y3llDeUp27TQ9v80tpSNh/dTEWiglbX2mkd//Gz/yDqjzIxc+KJIZq6Lcosap+OBqIjsv1EQIEuY9yEeJgJZ4S59IwJ7fMamlp452htaiir5Z2jdewsq+XFt4/R1HIieAtiQWZ3CvrUG8akrDDRQJRoIEpxvLi7h+2k1bVSlahqD/wXNr5A/vR8Dtcf5nBdathevp3jjSf/6mJWMKvbwM8OZhMPxokFY2QFs4gH40T9Ue3xy6Ao0OWUEwn6mD8lm/lTOh/V0tLq2F9Rz86yVNjvTIf9r7ccoqrhxJEykYCPaelDMKflRZmWF2Fafmp8am6UcMDXab0ZlkFuOJfccC6zmU1dZh0l80tOqquppYkj9UfaQ77j+OG6w2w+upmqRFWPzyvDMogFYsSD8RNDIN55OhgnFki9CcSCsU5tYsEY/gz9S49n+uuLZ/gyjOn5mUzPz+T9ZxW1z3fOcbyuqT3o3ymro7SintLyel565xj1TS2d1jMhHkoHfYfQTwd+YaznL02DvmD7oZQ9qW+u52jDUWqaaqhuqqamqYbaptr26drm1HjbUFpb2r68trm2z20Q8UeIB+JkJDO4/+n7U58AAh3CP/0GkB3OJjeUS04oh5xQDrnhXF062QMU6OJ5ZkZBLERBLMQFs/I7LWsL+33lqYDfd7yefeWpYf2u4zy+6UB7fz1AyJ9BXshx+q5XmZIbYUpOhKm5qWFKTpQJ8RAZGT13m0QDUaYHpg/oebS0tlCXrKM60Tn4u74J1DbXsuvALsL+MFWNVeyv2d++rOMx/SfV5o+SG84lO5QO+3AOuaHupzMDmUQDUSL+CGFfWF1FY4QCXca1jmG/eFruScsTyRYOVDRQWtHQHvobt+/leF2CLfsrqajvHJABnzEpOxX0U9qDPj2eE2Vidpigf2CXH/Zl+MgKZpEVzOqz7bp16ygpKTn5+bQkqE5UU5mobB8qGiuoSlRRkaigsrGSikRqem/1XioTlX1+MjAs9Z2EPxXw7eOByIl5/mj7G0DUH+VAzQESexLEA3Eyg5nEAjEyA5nEg3Ei/ogu0TxACnSRXoT8PmYVxphVGGufty56hJKSiwCoSyQ5WNnA/soG9lc0cKCigQOVDRyoqOfFt49SVpPotIdvBkXxMEVZIQrTtxPiYSZkhZgQD1GUFWZCPER+LISvlz39AT8fX4jCaCGF0cJ+36e5pZmqpioqGiva3wTqm+upT9ZT31xPQ7Khfbw+mZpuaG6gOlHN4drDnZY3tTa1r/enz/+028czjMxAJrFgrD3o28bbpiP+SOrTgT9M1B8l7A8T9oWJBFKfGNqWt7WJ+CPj4vsF7z9DkWGUGfIzpyjOnKJ4t8sTyRYOVTamQz4V/AcqGiiraWR/RT0b95aftJcPqcMx82OhE4EfTwX+hHTgF8ZTnyoK46GTvsQdagFfgIJIAQWRgr4b9yHZmqQ+Wc9zLzzH/CXzqWuuo7a5ltqmWmqba7udrmmqoTpRzcHag9Q11VHTXENjshGH6/sBO/Bn+In4UgEfyAjgz/Djy/Dhz/DjN3/qNj1UV1bz6LOPdprvy/C1T4d8IUL+EGFfmJAvRNifug35QkT8kZPmtY2HfeH28eHoplKgiwyjkN/HjIJMZhRk9timKdnK0doEZdWNlNV0vE1QVtPIkepGXj9QxbHaznv7beJhP4WxEAXxEIXpkK852sSRzH2dgj8/MzTg7p6h4s/wkxXMItefy5zcOQNej3OOREuChmQDjclGGloaTox3uG0b2ue3pG6TrUmaW5tpaW0h2ZqkxaVuk61Jki5Jk2uiorGi8/z0smRrkkRLgkQy0ekTx7vxpfO/xHVnXjfg598TBbrIKAv6M1L97DmRXtslW1o5XtdEWXWCY7UJjtYkONrh9lhNgm2Hq3nh7QQ1jUl++fbrJ60jJxqgMBYiLzPYPuRnBsltHw+Rmxlovw35h3fvf6DMLNXN4g8Py/p7+g6iq1bXSqIlQWOysfNtSyOJZPo2Pb/jvAWFC4albgW6yCnC78ugKCtMUVbfIfbMc2uZu/h8jtU2pQK/5sSbwLHaBMfrmni7rJaKuiYq6pvaL5bWVSzk7xT+bW8AOdEgOdEAOZFA+3hu+na4u4DGkgzLaO+rHwsU6CIeFPRZ6gdKcvu+9EBLq6OqoZnyugTldanb43VNVNQ1cbyuifL0cKS6kW2Hqjle10RTsrXH9YUDGeRE0oEfDZATCZKbGSA7EiQ3PW/f4SSBncfICgfIivjJCgeIh/34fTq6ZTAU6CLjnC/D2ve++8M5R2NzK5UNTVTUNVPZ0ERlfTOV9c1U1DdR1dBMZX0TFfXNVNU3887RWir3peY1t5z4KHDvpldOWndm0EdWJHBS0J88L0As7E8tC/uJhVLtokHfuD4mXoEuIu+KmREJ+ogEI0zK7n9Xg3OO+qYWKhua+f2LL3P6vAVUNyapbmimurGZ6oZk+vbE9OHqRnaUpcZrGpt77Bpqk2GpbqJ4+o0gNaTGu86PhdJD2E88/YYQS8933X37fApQoIvIiDAzMkN+MkN+iuMZnN/lrN2+tLY66pqSVDemwr22MUlNY5KaRGq6pjGZntecnpcaL6tp5J2jyfb2HS/g1hOfQdaLz6QDPkA8dCLsY2E/mUEfkWDqNtphPBL0kRnyEwmkbqPp5dGgf1jOK+hKgS4ip4SMDEvvYQeAgX8J2djcQl068Gs73NYm0m8SiSRbd+wir2hy+3RtY5KjNQl2H6ujprGZ+qaWk64B1JeQP6M93P/58jO4etGUAT+HnijQRWRcCQd8hAM+8nu50No69lNSMr/X9bS2OhqTqWCvT7RQ35ykLtFCQ1MLdU3JTrf1HeclWpiQNTy/jKVAFxEZgIwMIxr0Ew36IdZ3+5GgY4RERDyiX4FuZsvMbLuZ7TSzL/bS7sNm5sxs6dCVKCIi/dFnoJuZD7gXuAKYC1xvZnO7aRcHPgecfHCpiIgMu/7soZ8H7HTO7XLONQGrgKu6afdV4C6g+59TFxGRYWV9HUBvZiuAZc65W9LTNwLnO+du69BmMfAl59yHzWwd8E/OuQ3drGslsBKgqKhoyapVqwZUdG1tLbHYGPkWohuqb3BU3+CN9RpV38BdeumlG51z3XdrO+d6HYAVwP0dpm8E7ukwnQGsA2akp9cBS/ta75IlS9xArV27dsD3HQmqb3BU3+CN9RpV38ABG1wPudqfLpcDQMdfvZ2antcmDswH1pnZHuACYLW+GBURGVn9CfTXgDlmNtPMgsB1wOq2hc65KudcgXNuhnNuBrAeWO666XIREZHh02egO+eSwG3AGmAb8Jhz7k0zu9PMlg93gSIi0j/9OlPUOfc08HSXeXf00LZk8GWJiMi7pTNFRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEf0KdDNbZmbbzWynmX2xm+W3m9lWM9tiZs+Z2fShL1VERHrTZ6CbmQ+4F7gCmAtcb2ZzuzT7M7DUOXcO8Avg60NdqIiI9K4/e+jnATudc7ucc03AKuCqjg2cc2udc/XpyfXA1KEtU0RE+mLOud4bmK0AljnnbklP3wic75y7rYf29wCHnXP/1s2ylcBKgKKioiWrVq0aUNG1tbXEYrEB3XckqL7BUX2DN9ZrVH0Dd+mll250zi3tdqFzrtcBWAHc32H6RuCeHtr+Dak99FBf612yZIkbqLVr1w74viNB9Q2O6hu8sV6j6hs4YIPrIVf9/XhDOAAUd5iemp7XiZldBnwJuMQ5l+jvu42IiAyN/vShvwbMMbOZZhYErgNWd2xgZouA7wPLnXNlQ1+miIj0pc9Ad84lgduANcA24DHn3JtmdqeZLU83+wYQA35uZpvMbHUPqxMRkWHSny4XnHNPA093mXdHh/HLhrguERF5l3SmqIiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEQp0ERGPUKCLiHiEAl1ExCMU6CIiHqFAFxHxCAW6iIhHKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh6hQBcR8QgFuoiIRyjQRUQ8QoEuIuIRCnQREY9QoIuIeIQCXUTEIxToIiIeoUAXEfEIBbqIiEco0EVEPEKBLiLiEf0KdDNbZmbbzWynmX2xm+UhM3s0vfwVM5sx5JWKiEivzDnXewMzH7AD+ACwH3gNuN45t7VDm88A5zjnPm1m1wHXOOf+urf1Ll261G3YsOFdF3z4C7dStfE1wqEQ0Fvt3Szr/akOmURTglAwNDIPNgCqb3DGen0w9msc0vpsyBuSSCQIhYZv+4XOWczEr317QPc1s43OuaXdLfP34/7nATudc7vSK1sFXAVs7dDmKuDL6fFfAPeYmbm+3i0Gor6cUFM5NLf9cXr5I9lJIyMi4BwkR/Yx3w3VNzhjvT4Y+zWOTH2u29H+CDjXIWOGQUPlsKy2P4E+BSjtML0fOL+nNs65pJlVAfnAsY6NzGwlsDI9WWtm2wdSNFDQdd1jjOobHNU3eGO9xvFd3wtvw389PNB7T+9pQX8Cfcg4534A/GCw6zGzDT195BgLVN/gqL7BG+s1qr7h0Z8vRQ8AxR2mp6bnddvGzPxANnB8KAoUEZH+6U+gvwbMMbOZZhYErgNWd2mzGrgpPb4C+P2w9J+LiEiP+uxySfeJ3wasAXzAA865N83sTmCDc2418EPgYTPbCZSTCv3hNOhum2Gm+gZH9Q3eWK9R9Q2DPg9bFBGRU4POFBUR8QgFuoiIR4zpQB/Llxwws2IzW2tmW83sTTP7XDdtSsysysw2pYc7Rqq+9OPvMbPX04990mm5lvLt9PbbYmaLR7C2Mzpsl01mVm1mn+/SZsS3n5k9YGZlZvZGh3l5ZvY7M3s7fZvbw31vSrd528xu6q7NMNT2DTN7K/33e9zMcnq4b6+vhWGu8ctmdqDD3/HKHu7b6//7MNb3aIfa9pjZph7uOyLbcFCcc2NyIPUF7DvALCAIbAbmdmnzGeB76fHrgEdHsL5JwOL0eJzU5RG61lcCPDWK23APUNDL8iuB35A6lfYC4JVR/FsfBqaP9vYDLgYWA290mPd14Ivp8S8Cd3VzvzxgV/o2Nz2eOwK1fRDwp8fv6q62/rwWhrnGLwP/1I/XQK//78NVX5fldwN3jOY2HMwwlvfQ2y854JxrAtouOdDRVcBD6fFfAO83sxE539k5d8g596f0eA2wjdQZs6eSq4Afu5T1QI6ZTRqFOt4PvOOc2zsKj92Jc+4FUkdqddTxdfYQcHU3d70c+J1zrtw5VwH8Dlg23LU5555xziXTk+tJnScyanrYfv3Rn//3QeutvnR2fBT42VA/7kgZy4He3SUHugZmp0sOAG2XHBhR6a6eRcAr3Sx+j5ltNrPfmNm8ka0MBzxjZhvTl13oqj/beCRcR8//RKO5/doUOecOpccPA0XdtBkL2/KTpD5xdaev18Jwuy3dLfRAD11WY2H7XQQccc693cPy0d6GfRrLgX5KMLMY8Evg88656i6L/0SqG2EB8B3giREu733OucXAFcCtZnbxCD9+n9Inqy0Hft7N4tHefidxqc/eY+5YXzP7EpAEftJDk9F8LdwHzAYWAodIdWuMRdfT+975mP9/GsuBPuYvOWBmAVJh/hPn3P/rutw5V+2cq02PPw0EzKxgpOpzzh1I35YBj5P6WNtRf7bxcLsC+JNz7kjXBaO9/To40tYVlb4t66bNqG1LM/sE8FfAx9JvOCfpx2th2DjnjjjnWpxzrcB/9/DYo/paTOfHtcCjPbUZzW3YX2M50Mf0JQfS/W0/BLY5577ZQ5uJbX36ZnYeqe09Im84ZpZpZvG2cVJfnr3Rpdlq4OPpo10uAKo6dC2MlB73ikZz+3XR8XV2E/CrbtqsAT5oZrnpLoUPpucNKzNbBvwLsNw5V99Dm/68Foazxo7fy1zTw2P35/99OF0GvOWc29/dwtHehv022t/K9jaQOgpjB6lvv7+UnncnqRcvQJjUR/WdwKvArBGs7X2kPnpvATalhyuBTwOfTre5DXiT1Df264H3jmB9s9KPuzldQ9v261ifAfemt+/rwNIR/vtmkgro7A7zRnX7kXpzOQQ0k+rH/RSp72WeA94GngXy0m2XAvd3uO8n06/FncDNI1TbTlJ9z22vwbajviYDT/f2WhjB7fdw+vW1hVRIT+paY3r6pP/3kagvPf/Bttddh7ajsg0HM+jUfxERjxjLXS4iIvIuKNBFRDxCgS4i4hEKdBERj1Cgi4h4hAJdRMQjFOgiIh7x/wEqQ10/iP+4HwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONAL API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada sebuah classification dia menggunakan output layer sebanyak n-jumlah klasifikasi dengan kalkulasi sesuai fungsi aktivasi dengan loss function adalah sebuha cross entropy \n",
    "\n",
    "TAPI\n",
    "\n",
    "regresion dia menggunakan single output layer dengan tidak menggunakan fungsi aktivasi yang mana loss function mengguanakn mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep pola\n",
    "input_ = keras.layers.Input(shape=X_train.shape[1:])#Feature => input\n",
    "# sebuah input_ di call like a function passing it input\n",
    "hidden1 = keras.layers.Dense(30, activation ='relu')(input_)\n",
    "# sebuah hidden1 di call like a function passing it input \n",
    "hidden2 = keras.layers.Dense(30,activation = 'relu')(hidden1)\n",
    "# make the concat layers for concate the hidden layers\n",
    "\n",
    "# concat = wide pola , deep pola\n",
    "concat = keras.layers.Concatenate()([input_,hidden2])\n",
    "\n",
    "# output layers = take two pola\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "\n",
    "# create model\n",
    "model= keras.Model(inputs=[input_],outputs=[output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8422 - accuracy: 0.0028 - val_loss: 0.7855 - val_accuracy: 0.0044\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.0029 - val_loss: 0.6893 - val_accuracy: 0.0044\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.6472 - accuracy: 0.0029 - val_loss: 0.6295 - val_accuracy: 0.0044\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.5944 - accuracy: 0.0029 - val_loss: 0.5954 - val_accuracy: 0.0044\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 970us/step - loss: 0.5538 - accuracy: 0.0029 - val_loss: 0.5587 - val_accuracy: 0.0044\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.5217 - accuracy: 0.0029 - val_loss: 0.5367 - val_accuracy: 0.0044\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.4970 - accuracy: 0.0029 - val_loss: 0.5165 - val_accuracy: 0.0044\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.4784 - accuracy: 0.0029 - val_loss: 0.5024 - val_accuracy: 0.0044\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.0029 - val_loss: 0.4907 - val_accuracy: 0.0044\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.4515 - accuracy: 0.0029 - val_loss: 0.4801 - val_accuracy: 0.0044\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mean_squared_error',optimizer=keras.optimizers.SGD(learning_rate=1e-3),metrics='accuracy')\n",
    "history=model.fit(X_train,y_train,epochs=10,validation_data=[X_valid,y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.842244</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.785489</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.725798</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.689284</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.647216</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.629541</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594412</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.595374</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553823</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.558656</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.521708</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.536738</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.497048</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.516545</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.478368</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.502409</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.463349</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.490693</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.451512</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.480058</td>\n",
       "      <td>0.004393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  1.842244  0.002842  0.785489      0.004393\n",
       "1  0.725798  0.002929  0.689284      0.004393\n",
       "2  0.647216  0.002929  0.629541      0.004393\n",
       "3  0.594412  0.002929  0.595374      0.004393\n",
       "4  0.553823  0.002929  0.558656      0.004393\n",
       "5  0.521708  0.002929  0.536738      0.004393\n",
       "6  0.497048  0.002929  0.516545      0.004393\n",
       "7  0.478368  0.002929  0.502409      0.004393\n",
       "8  0.463349  0.002929  0.490693      0.004393\n",
       "9  0.451512  0.002929  0.480058      0.004393"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b21892ebdafe3dff83e5313b97a9ee6f28f1dc2886ff01f2f955fb4cde4b09b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
